{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b14884f-2059-4df5-8df4-c2f5821d8af4",
   "metadata": {},
   "source": [
    "# 簡介\n",
    "我們先來看看 Scikit learn 提供哪些資料\"玩具資料集\"，\n",
    "為什麼稱為玩具資料，因為實際處理的資料格式不會這麼統一，可能會有缺失資料。\n",
    "在開始訓練模型之前有一份工作叫做 data cleaning 資料清洗，要把實際收到的資料格式統一，再把缺失資料補上等等操作。\n",
    "而玩具資料的特點一是資料量不多，特點二是格式都統一也沒有缺失資料，非常適合用來學習機器學習。\n",
    "\n",
    "\n",
    "\n",
    "# Iris plants dataset. 鳶尾植物數據集\n",
    "\n",
    "一次看太多會失去樂趣，我們先來看這個資料集。\n",
    "\n",
    "* Number of Instances: <font color=#0000FF>$50$</font> <br>\n",
    "  這個資料集有 $50$ 筆資料。\n",
    "* Number of Attributes: 4 <br>\n",
    "  每筆資料有 $4$ 個特徵。\n",
    "\n",
    "\n",
    "## Attributes 特徵分別是\n",
    "我們來英文翻譯，花萼（sepal）和花瓣（petal），長度（length）和寬度（width）。\n",
    "\n",
    "1. sepal length in cm， 花萼 的 長度。\n",
    "2. sepal width in cm， 花萼 的 寬度。\n",
    "3. petal length in cm， 花瓣 的 長度。\n",
    "4. petal width in cm， 花瓣 的 寬度。\n",
    "\n",
    "\n",
    "## Class\n",
    "要分類的是鳶尾花屬下的三個亞屬，分別是山鳶尾（setosa）、變色鳶尾（verscicolor）和維吉尼亞鳶尾（virginica）。\n",
    "\n",
    "1. Setosa， 山鳶尾\n",
    "2. Versicolour， 變色鳶尾\n",
    "3. Virginica， 維吉尼亞鳶尾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d76ea43-4f10-4210-b680-5d46ba8a54ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X:  (150, 4)  The shape of y:  (150,)\n"
     ]
    }
   ],
   "source": [
    "# 得到資料 方法一: 直接得到 X, y \n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "print('The shape of X: ', X.shape, ' The shape of y: ', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bc7a9d-0b7e-4857-b821-a83375790a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3\n",
       "count  150.000000  150.000000  150.000000  150.000000\n",
       "mean     5.843333    3.057333    3.758000    1.199333\n",
       "std      0.828066    0.435866    1.765298    0.762238\n",
       "min      4.300000    2.000000    1.000000    0.100000\n",
       "25%      5.100000    2.800000    1.600000    0.300000\n",
       "50%      5.800000    3.000000    4.350000    1.300000\n",
       "75%      6.400000    3.300000    5.100000    1.800000\n",
       "max      7.900000    4.400000    6.900000    2.500000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X_df = pd.DataFrame(X)\n",
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eaf39a-dc59-4029-9fcd-1847ea92baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到資料 方法二: 先拿到資料物件，再得到 X, y\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "\n",
    "print('The data features:')\n",
    "display(data.feature_names)\n",
    "\n",
    "X = data.data\n",
    "print('The shape of X: ', X.shape, '\\n')\n",
    "\n",
    "print('The class names:')\n",
    "display(data.target_names)\n",
    "\n",
    "y = data.target\n",
    "print('The shape of y: ', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f94703-4ac0-477d-b15f-005066f76a34",
   "metadata": {},
   "source": [
    "# Diabetes dataset. 糖尿病數據集\n",
    "\n",
    "* Number of Instances: <font color=#0000FF>$442$</font> <br>\n",
    "  這個資料集有 $442$ 筆資料。\n",
    "* Number of Attributes: 10 <br>\n",
    "  每筆資料有 $10$ 個特徵。\n",
    "\n",
    "\n",
    "## Attributes 特徵分別是\n",
    "\n",
    "1. age in years， 年紀。\n",
    "2. sex， 性別。\n",
    "3. bmi body mass index。\n",
    "4. bp average blood pressure。\n",
    "5. s1 tc, total serum scholesterol\n",
    "6. s2 ldl, low-density lipoproteins\n",
    "7. s3 hdl, high-density lipoproteins\n",
    "8. s4 tch, total cholesterol / HDL\n",
    "9. s5 ltg, possibly log of serum triglycerides level\n",
    "10. s6 glu, blood sugar level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba0e10-1f46-4f2c-acbf-7c0e490b43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接得到 X, y \n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "print('The shape of X: ', X.shape, ' The shape of y: ', y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604a548-1672-414b-888c-2852d1db548b",
   "metadata": {},
   "source": [
    "當我們需要更大量的資料來測試的時候，我們可以使用 scikit learn 的 Generated datasets 來隨機生成我們想要的數據。\n",
    "\n",
    "\n",
    "# Generated datasets 生成的數據集\n",
    "\n",
    "* make_blobs\n",
    "* make_classification\n",
    "* make_gaussian_quantiles\n",
    "* make_biclusters\n",
    "* make_blobs\n",
    "* make_checkerboard\n",
    "* make_circles\n",
    "* make_classification\n",
    "* make_friedman1\n",
    "* make_friedman2\n",
    "* make_friedman3\n",
    "* make_gaussian_quantiles\n",
    "* make_hastie_10_2\n",
    "* make_low_rank_matrix\n",
    "* make_moons\n",
    "* make_multilabel_classification\n",
    "* make_regression\n",
    "* make_s_curve\n",
    "* make_sparse_coded_signal\n",
    "* make_sparse_spd_matrix\n",
    "* make_sparse_uncorrelated\n",
    "* make_spd_matrix\n",
    "* make_swiss_roll\n",
    "\n",
    "\n",
    "我們下面簡單來看 make_classification 的用法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bd78d6-99ef-43c7-ba55-77585ffc1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接得到 X, y \n",
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=1000, n_features=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4cae9e-630b-45b2-956f-6f0aef35dc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "536a8686-343a-41f1-bbbc-24eef564cb67",
   "metadata": {},
   "source": [
    "下面我們會開始準備你的第一戰，\n",
    "我們先準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87f7185-4c31-4f1b-aa27-b00a55f8d74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X:  (150, 4)  The shape of y:  (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "print('The shape of X: ', X.shape, ' The shape of y: ', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc73f17-dfa6-4b5e-891a-08aa46a7a16d",
   "metadata": {},
   "source": [
    "我們先準備基準模型 (baseline model)，假設我們無腦猜1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc09efaf-55fa-464b-b35b-870c2f1f190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答對  50 題，準確率:  0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for flag in y == 2:\n",
    "    if flag:\n",
    "        count += 1\n",
    "\n",
    "print('答對 ', count, '題，準確率: ', count/len(y))\n",
    "\n",
    "\n",
    "# 以後會教的比較高級 baseline model 使用方法\n",
    "from sklearn.dummy import DummyClassifier\n",
    "baseline_model = DummyClassifier(strategy='constant', constant=1, random_state=87)\n",
    "baseline_model.fit(X, y)\n",
    "\n",
    "baseline_model.score(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfb030-6508-4081-85fd-b693a37f7259",
   "metadata": {},
   "source": [
    "我們先來切分資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73bfece-a0a3-4936-a585-607718a9a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分資料\n",
    "X_train = X[:-30]\n",
    "X_test  = X[-30:]\n",
    "\n",
    "y_train = y[:-30]\n",
    "y_test  = y[-30:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127cde2-b0fb-4f2c-86e5-d921059e7c98",
   "metadata": {},
   "source": [
    "我們下面展示一下流程，不用太在意模型的原理我們之後會詳細解釋。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c761f46f-508f-476f-bf0e-a059d1b22233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "models = (\n",
    "    svm.SVC(kernel=\"linear\", C=C),\n",
    "    svm.LinearSVC(C=C, max_iter=10000),\n",
    "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
    "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
    ")\n",
    "\n",
    "models = (clf.fit(X_train, y_train) for clf in models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08976985-1c9c-4a44-a3f7-06d4520c78de",
   "metadata": {},
   "source": [
    "我們來看看訓練完的模型效果如何，我們可以檢討一下切分資料為何不好，我們可以列印出 $X$ 與 $y$ 的資料來看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80f6ea-29df-4b95-9d50-39e7ad9cce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in models:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3ac1a-efad-46e3-8218-d6f88215b56c",
   "metadata": {},
   "source": [
    "好像還可以，我們下面介紹一種常用的切分資料的方法，稱為Holdout Method，切為 train ， test 集合，我們在以後cross-validation的章節會詳細介紹其他方法，我們現在就先來試試他的威力八。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b33e2cf5-edc8-4b27-96ea-c03fc977c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f987fa19-7c20-4a30-a3aa-4cf54c7f1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "models = (\n",
    "    svm.SVC(kernel=\"linear\", C=C),\n",
    "    svm.LinearSVC(C=C, max_iter=10000),\n",
    "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
    "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
    ")\n",
    "\n",
    "models = (clf.fit(X_train, y_train) for clf in models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdf3a6b1-571c-4bdd-8d8f-7704bad10950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in models:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1155af27-4f28-4793-b6f1-d89c65e259dc",
   "metadata": {},
   "source": [
    "恭喜你完成人生的第一場戰鬥，下面我們要介紹一些很重要的概念，```over fitting``` 跟 ```under fitting```。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dff387",
   "metadata": {},
   "source": [
    "![alt fitting](../../images/fitting_problem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932cd6f2",
   "metadata": {},
   "source": [
    "你已經完成人生的第一場戰鬥，但是打鐵要趁熱，我們先來說說妳以後訓練模型可能會碰到的問題，\n",
    "模型的錯誤可以簡單分為 Bias 與 Variance的大小，我們以後會介紹ensemble方法，\n",
    "我們看完下面的圖就可以理解ensemble的投票(voting)與平均(mean)為何可以增加模型的準度，\n",
    "但是我在這邊也要潑一下冷水，在實務上除非你做的模型沒有時間壓力，\n",
    "不然通常不會採用 ensemble 強化你的模型的準確度。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e167c5c",
   "metadata": {},
   "source": [
    "![alt bias-variance](../../images/bias-and-variance_orig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41f4b3-20af-4a55-9174-947502cf6778",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "下面來簡單介紹 ensemble 的方法，可以分為兩大類\n",
    "\n",
    "- 平均法 averaging methods <br>\n",
    "例如我們可以訓練許多中型的模型 (Low Bias)，然後讓他們投票，\n",
    "就有可能給出 Low Bias 跟 Low Variance 的更好的模型。\n",
    "\n",
    "- 提升法 boosting methods <br>\n",
    "我們還有另一個思路，三個臭皮匠勝過一個諸葛亮，我們一個打不過，可以不講武德車輪戰一個一個上阿，\n",
    "每次進步一點，那多輪以後就有一個強大的模型。 <br>\n",
    "下面舉個例子，假設我們要做的問題是二分類問題，如果隨便猜，猜對的機率因該是 $1/2$，\n",
    "假設我們有一個方法可以比亂猜的機率高一點，假設是 $1/2 + 0.00001$，\n",
    "那我們可以給他好幾關。\n",
    "\n",
    "![boosting](../../images/boosting_method.drawio.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ad098c-87b5-420f-af2f-b800c8a4a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第  1  次答對機率:  0.50001\n",
      "第  2  次答對機率:  0.7500099999\n",
      "第  3  次答對機率:  0.8750074998500009\n",
      "第  4  次答對機率:  0.937504999850002\n",
      "第  5  次答對機率:  0.9687531248750025\n",
      "第  6  次答對機率:  0.9843768749062525\n",
      "第  7  次答對機率:  0.9921885936843772\n",
      "第  8  次答對機率:  0.9960943749562517\n",
      "第  9  次答對機率:  0.9980472265343763\n",
      "第  10  次答對機率:  0.9990236327949228\n"
     ]
    }
   ],
   "source": [
    "# 可以答對的機率\n",
    "q = 0.5 + 0.00001\n",
    "# 錯誤的機率\n",
    "err_rate = 1 - q\n",
    "\n",
    "for i in range(10):\n",
    "    print('第 ', i+1, ' 次答對機率: ', 1 - err_rate)\n",
    "    err_rate = err_rate * (1-q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3272d8a-0acf-4a58-bb92-9058252a024b",
   "metadata": {},
   "source": [
    "### 總結\n",
    "\n",
    "平均法(例如 voting 或 bagging)對於每個強大與複雜的模型還要在更進一步的提升非常有效，\n",
    "也可以緩解 over fitting 等問題，但是如果拿來平均的模型有老鼠屎，\n",
    "ensemble 的模型會不升反降，\n",
    "提升法去整合弱模型有良好的表現。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed0ce5-2be1-4874-8640-bf93e7a9e93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f570df-6397-4f5a-b562-c41740c8c70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('toby')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f507bc0c6a586295e3338d11ec3fe19c4f242dbc5a06bb50ca7be29aa175c9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
