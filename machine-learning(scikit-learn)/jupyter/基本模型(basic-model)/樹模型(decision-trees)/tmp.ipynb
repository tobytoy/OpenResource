{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "https://ithelp.ithome.com.tw/articles/10271143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaseDecisionTree',\n",
       " 'DecisionTreeClassifier',\n",
       " 'DecisionTreeRegressor',\n",
       " 'ExtraTreeClassifier',\n",
       " 'ExtraTreeRegressor',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_classes',\n",
       " '_criterion',\n",
       " '_export',\n",
       " '_reingold_tilford',\n",
       " '_splitter',\n",
       " '_tree',\n",
       " '_utils',\n",
       " 'export_graphviz',\n",
       " 'export_text',\n",
       " 'plot_tree']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dir(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseDecisionTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"A decision tree classifier.\n",
      "\n",
      "    Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "\n",
      "    splitter : {\"best\", \"random\"}, default=\"best\"\n",
      "        The strategy used to choose the split at each node. Supported\n",
      "        strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "        the best random split.\n",
      "\n",
      "    max_depth : int, default=None\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "            - If int, then consider `max_features` features at each split.\n",
      "            - If float, then `max_features` is a fraction and\n",
      "              `int(max_features * n_features)` features are considered at each\n",
      "              split.\n",
      "            - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"log2\", then `max_features=log2(n_features)`.\n",
      "            - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the randomness of the estimator. The features are always\n",
      "        randomly permuted at each split, even if ``splitter`` is set to\n",
      "        ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
      "        select ``max_features`` at random at each split before finding the best\n",
      "        split among them. But the best found split may vary across different\n",
      "        runs, even if ``max_features=n_features``. That is the case, if the\n",
      "        improvement of the criterion is identical for several splits and one\n",
      "        split has to be selected at random. To obtain a deterministic behaviour\n",
      "        during fitting, ``random_state`` has to be fixed to an integer.\n",
      "        See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    class_weight : dict, list of dict or \"balanced\", default=None\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If None, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
      "        The classes labels (single output problem),\n",
      "        or a list of arrays of class labels (multi-output problem).\n",
      "\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The impurity-based feature importances.\n",
      "        The higher, the more important the feature.\n",
      "        The importance of a feature is computed as the (normalized)\n",
      "        total reduction of the criterion brought by that feature.  It is also\n",
      "        known as the Gini importance [4]_.\n",
      "\n",
      "        Warning: impurity-based feature importances can be misleading for\n",
      "        high cardinality features (many unique values). See\n",
      "        :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    n_classes_ : int or list of int\n",
      "        The number of classes (for single output problems),\n",
      "        or a list containing the number of classes for each\n",
      "        output (for multi-output problems).\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "        .. deprecated:: 1.0\n",
      "           `n_features_` is deprecated in 1.0 and will be removed in\n",
      "           1.2. Use `n_features_in_` instead.\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    tree_ : Tree instance\n",
      "        The underlying Tree object. Please refer to\n",
      "        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "        for basic usage of these attributes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DecisionTreeRegressor : A decision tree regressor.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The :meth:`predict` method operates using the :func:`numpy.argmax`\n",
      "    function on the outputs of :meth:`predict_proba`. This means that in\n",
      "    case the highest predicted probabilities are tied, the classifier will\n",
      "    predict the tied class with the lowest index in :term:`classes_`.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      "\n",
      "    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      "           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      "\n",
      "    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      "           Learning\", Springer, 2009.\n",
      "\n",
      "    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      "           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> from sklearn.tree import DecisionTreeClassifier\n",
      "    >>> clf = DecisionTreeClassifier(random_state=0)\n",
      "    >>> iris = load_iris()\n",
      "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      "    ...                             # doctest: +SKIP\n",
      "    ...\n",
      "    array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      "            0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"best\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msplitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mccp_alpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"deprecated\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Build a decision tree classifier from the training set (X, y).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csc_matrix``.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The target values (class labels) as integers or strings.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If None, then samples are equally weighted. Splits\n",
      "            that would create child nodes with net zero or negative weight are\n",
      "            ignored while searching for a split in each node. Splits are also\n",
      "            ignored if they would result in any single class carrying a\n",
      "            negative weight in either child node.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        X_idx_sorted : deprecated, default=\"deprecated\"\n",
      "            This parameter is deprecated and has no effect.\n",
      "            It will be removed in 1.1 (renaming of 0.26).\n",
      "\n",
      "            .. deprecated:: 0.24\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : DecisionTreeClassifier\n",
      "            Fitted estimator.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "        The predicted class probability is the fraction of samples of the same\n",
      "        class in a leaf.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n",
      "            such arrays if n_outputs > 1\n",
      "            The class probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mnormalizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mproba\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mall_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mnormalizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mall_proba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class log-probabilities of the input samples X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n",
      "            such arrays if n_outputs > 1\n",
      "            The class log-probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"The attribute `n_features_` is deprecated in 1.0 and will be removed \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"in 1.2. Use `n_features_in_` instead.\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mn_features_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\tobywang\\anaconda3\\envs\\toby\\lib\\site-packages\\sklearn\\tree\\_classes.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     ExtraTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "??tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://blog.csdn.net/qq_43391414/article/details/109382789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost\n",
    "https://medium.com/@houyitong/adaboost%E4%BB%8B%E7%B4%B9-%E4%B8%8A-%E6%BC%94%E7%AE%97%E6%B3%95%E4%BB%8B%E7%B4%B9-894fe049ad76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('toby')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f507bc0c6a586295e3338d11ec3fe19c4f242dbc5a06bb50ca7be29aa175c9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
